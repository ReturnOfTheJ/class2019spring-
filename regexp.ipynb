{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정규표현에 대한 간단한 예제와 그 활용성을 알 수 있는 간단한 예시를 몇 가지 들어보았다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "jang 950325-*******\n",
      "jeon 980226-*******\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data='''\n",
    "jang 950325-1030210\n",
    "jeon 980226-2030211\n",
    "'''\n",
    "\n",
    "result=[]\n",
    "for line in data.split('\\n'):\n",
    "    word_result=[]\n",
    "    for word in line.split(' '):\n",
    "        if len(word) == 14 and word[:6].isdigit() and word[7:].isdigit():\n",
    "            word=word[:6] + '-' + '*******'\n",
    "        word_result.append(word)\n",
    "    result.append(' '.join(word_result))\n",
    "print('\\n'.join(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "jang 950325-******\n",
      "jeon 980226-******\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data='''\n",
    "jang 950325-1030210\n",
    "jeon 980226-2030211\n",
    "'''\n",
    "\n",
    "pat=re.compile('(\\d{6})[-]\\d{7}')\n",
    "print(pat.sub('\\g<1>-******',data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=re.compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "p=re.compile('[a-z]+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(0, 6), match='python'>\n"
     ]
    }
   ],
   "source": [
    "m=p.match('python')\n",
    "print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "m=p.match('3python')\n",
    "print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match found: m\n"
     ]
    }
   ],
   "source": [
    "p=re.compile('[a-z]')\n",
    "m=p.match('maple')\n",
    "if m:\n",
    "    print('Match found:', m.group())\n",
    "else:\n",
    "    print('No match')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(0, 1), match='p'>\n"
     ]
    }
   ],
   "source": [
    "m=p.search('python')\n",
    "print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(1, 2), match='p'>\n"
     ]
    }
   ],
   "source": [
    "m=p.search('3python')\n",
    "print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['h', 'e', 'l', 'l', 'o', 'w', 'o', 'r', 'l', 'd']\n"
     ]
    }
   ],
   "source": [
    "result=p.findall('hello world')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<callable_iterator object at 0x0000009672811860>\n"
     ]
    }
   ],
   "source": [
    "result=p.finditer('hello world')\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(0, 1), match='h'>\n",
      "<re.Match object; span=(1, 2), match='e'>\n",
      "<re.Match object; span=(2, 3), match='l'>\n",
      "<re.Match object; span=(3, 4), match='l'>\n",
      "<re.Match object; span=(4, 5), match='o'>\n",
      "<re.Match object; span=(6, 7), match='w'>\n",
      "<re.Match object; span=(7, 8), match='o'>\n",
      "<re.Match object; span=(8, 9), match='r'>\n",
      "<re.Match object; span=(9, 10), match='l'>\n",
      "<re.Match object; span=(10, 11), match='d'>\n",
      "<re.Match object; span=(12, 13), match='m'>\n",
      "<re.Match object; span=(13, 14), match='r'>\n",
      "<re.Match object; span=(15, 16), match='y'>\n",
      "<re.Match object; span=(16, 17), match='e'>\n",
      "<re.Match object; span=(17, 18), match='s'>\n",
      "<re.Match object; span=(18, 19), match='t'>\n",
      "<re.Match object; span=(19, 20), match='e'>\n",
      "<re.Match object; span=(20, 21), match='r'>\n",
      "<re.Match object; span=(21, 22), match='d'>\n",
      "<re.Match object; span=(22, 23), match='a'>\n",
      "<re.Match object; span=(23, 24), match='y'>\n"
     ]
    }
   ],
   "source": [
    "for r in result:print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python\n",
      "0\n",
      "6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0, 6)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "p=re.compile('[a-z]+')\n",
    "m=p.match('python')\n",
    "print(m.group())\n",
    "print(m.start())\n",
    "print(m.end())\n",
    "m.span()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python\n",
      "2\n",
      "8\n",
      "(2, 8)\n"
     ]
    }
   ],
   "source": [
    "m=p.search('3 python')\n",
    "print(m.group())\n",
    "print(m.start())\n",
    "print(m.end())\n",
    "print(m.span())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제부터는 수업 내용입니다.\n",
    "늘 하던대로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "마찬가지로, 자연어처리와 정규표헌식은 매우 긴밀한 관계가 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('words')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위에서 다운받은 패키지가 바로 natural language tool kit에 내장된 백과사전이다.\n",
    "여러가지 기능을 수행할 수 있다. \n",
    "정규표현에서 $는 접미사를, ^는 접두사를의미한다. 단, ^이 []안에 들어있는 경우 first가 아니라 not의 의미를 갖는다. .은 흔히들 joker라고도 하고 wildcard 라고도 한다. 어떠한 요소가 와도 된다는 뜻이다. []안에 있는 단어는 택1 이라는 뜻으로, [abc][def][ghi]이렇게 되어있는 경우 나올 수 있는 단어조합은 27가지가 되는 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'aa', 'aal', 'aalii', 'aam', 'aardvark', 'aardwolf', 'aba', 'abac', 'abaca']\n",
      "['abaissed', 'abandoned', 'abased', 'abashed', 'abatised', 'abed', 'aborted', 'abridged', 'abscessed', 'absconded']\n",
      "['abjectly', 'adjuster', 'dejected', 'dejectly', 'injector', 'majestic', 'objectee', 'objector', 'rejecter', 'rejector']\n",
      "['a', 'aa', 'ah', 'aha', 'h', 'ha', 'hah']\n",
      "['gold', 'golf', 'hold', 'hole']\n"
     ]
    }
   ],
   "source": [
    "wordlist=[w for w in nltk.corpus.words.words('en') if w.islower()]\n",
    "print(wordlist[:10])\n",
    "result=[w for w in wordlist if re.search('ed$',w)][:10]\n",
    "print(result[:10])\n",
    "result=[w for w in wordlist if re.search('^..j..t..$',w)][:10]\n",
    "print(result[:10])\n",
    "result=[w for w in wordlist if re.search('^[ah]+$', w)][:10]\n",
    "print(result[:10])\n",
    "result=[w for w in wordlist if re.search('^[ghi][mno][jlk][def]$', w)][:10]\n",
    "print(result[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사전작업"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package treebank to\n",
      "[nltk_data]     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package treebank is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('treebank')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이번에는 nltk에 내장된 패키지 중 월스트리트저널에 탑재된 단어들을 살펴보기로 했다. []안에 문자가 아니라 숫자가 들어갈 경우에도 택1을 의미하게 되는데 0-9 혹은 a-z 혹은 A-Z처럼 범위가 있는 경우에는 그 중에서 하나 라고 해석하기보다는 모든 숫자중 하나, 모든 알파벳 소문자 중 하나 사실상 조건을 만족하는 요소 무엇이 와도 된다는 것을 의미한다고 보는 것이 편하다. 참고로 | <-이것은 or 의 의미로서 [a-z|0-9]이런 식으로 되어있다면 숫자나 문자 무엇이 와도 될 것이다. []대괄호로 묶여있기 때문에 출력되는 요소는 반드시 단 하나이다. {}중괄호로 묶여있는 것은 원래는 loop를 몇 번 도느냐인데 요소의 개수를 결정한다고 보는것이 편하다. 단 python에 적용되는 range(0,3)일때 0이상 3미만 이라는 이상미만개념이 {}에서는 3이상5미만이 아니라 3이상 5'이하'로 바뀐다는 점을 유의해야 한다. 출력되는 모든 값은 list의 형태로 등장한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0.0085', '0.05', '0.1', '0.16', '0.2', '0.25', '0.28', '0.3', '0.4', '0.5']\n",
      "['C$', 'US$']\n",
      "['1614', '1637', '1787', '1901', '1903', '1917', '1925', '1929', '1933', '1934']\n",
      "['10-day', '10-lap', '10-year', '100-share', '12-point', '12-year', '14-hour', '15-day', '150-point', '190-point']\n",
      "['black-and-white', 'bread-and-butter', 'father-in-law', 'machine-gun-toting', 'savings-and-loan']\n",
      "['62%-owned', 'Absorbed', 'According', 'Adopting', 'Advanced', 'Advancing', 'Alfred', 'Allied', 'Annualized', 'Anything']\n",
      "[]\n",
      "['238,000-circulation', '62%-owned', 'Absorbed', 'According', 'Acquisition', 'Administration', 'Adopting', 'Advanced', 'Advancing', 'Alfred']\n"
     ]
    }
   ],
   "source": [
    "wsj=sorted(set(nltk.corpus.treebank.words()))\n",
    "wordlist=[w for w in wsj if re.search('^[0-9]+\\.[0-9]+$',w)]\n",
    "print(wordlist[:10])\n",
    "wordlist=[w for w in wsj if re.search('^[A-Z]+\\$$', w)]\n",
    "print(wordlist[:10])\n",
    "wordlist=[w for w in wsj if re.search('^[0-9]{4}$',w)]\n",
    "print(wordlist[:10])\n",
    "wordlist=[w for w in wsj if re.search('^[0-9]+-[a-z]{3,5}$',w)]\n",
    "print(wordlist[:10])\n",
    "wordlist=[w for w in wsj if re.search('^[a-z]{5,}-[a-z]{2,3}-[a-z]{,6}$',w)]\n",
    "print(wordlist[:10])\n",
    "wordlist=[w for w in wsj if re.search('(ed|ing)$',w)]\n",
    "print(wordlist[:10])\n",
    "wordlist=[w for w in wsj if re.search('^[0-9]{0,2}-[a-z]{5,}-(ed|ing|tion)$',w)]\n",
    "print(wordlist[:10])\n",
    "wordlist=[w for w in wsj if re.search('(ed|ing|tion)$',w)]\n",
    "print(wordlist[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fa']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall('fa', 'ababdddabkagadshafhfdhdfghsdhsdffdhdshdfaaggaagbdasdd')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "findall 과 가장 빈번하게 쓰인 것 역시 찾아낼 수 있다. list로 출력되는 것은 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('io', 549),\n",
       " ('ea', 476),\n",
       " ('ie', 331),\n",
       " ('ou', 329),\n",
       " ('ai', 261),\n",
       " ('ia', 253),\n",
       " ('ee', 217),\n",
       " ('oo', 174),\n",
       " ('ua', 109),\n",
       " ('au', 106),\n",
       " ('ue', 105),\n",
       " ('ui', 95),\n",
       " ('ei', 86),\n",
       " ('oi', 65),\n",
       " ('oa', 59),\n",
       " ('eo', 39),\n",
       " ('iou', 27),\n",
       " ('eu', 18),\n",
       " ('oe', 15),\n",
       " ('iu', 14),\n",
       " ('ae', 11),\n",
       " ('eau', 10),\n",
       " ('uo', 8),\n",
       " ('oui', 6),\n",
       " ('ao', 6),\n",
       " ('eou', 5),\n",
       " ('uou', 5),\n",
       " ('uee', 4),\n",
       " ('aa', 3),\n",
       " ('ieu', 3)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist=nltk.FreqDist(vs for word in wsj for vs in re.findall(r'[aeiou]{2,}',word))\n",
    "fdist.most_common(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "supercali..... 이 단어에서 findall 함수를 활용해보자. 모음만 색인하기, 모음 사이에 있는 세글자 요소를 색인하기등이 있는데, 여기서 주목할 점은 +와 ?의 차이이다. 모두 복수의 요소를 추출할 때 사용하는 정규표현식인데 +는 1부터 시작하고 ?는 0부터 시작한다는 엄청난 차이점이 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['u', 'e', 'a', 'i', 'a', 'i', 'i', 'i', 'e', 'i', 'a', 'i', 'o', 'i', 'o', 'u']\n",
      "['gil', 'xpi', 'doc']\n",
      "['supercalifragilisticexpialidocious']\n",
      "['sup', 'rcal', 'frag', 'lis', 'tic', 'xpial', 'doc']\n"
     ]
    }
   ],
   "source": [
    "word='supercalifragilisticexpialidocious'\n",
    "result=re.findall(r'[aeiou]',word)\n",
    "print(result)\n",
    "result=re.findall('[aeiou](...)[aeiou]',word)\n",
    "print(result)\n",
    "result=re.findall('[^aeiou].+[^aeiou]',word)\n",
    "print(result)\n",
    "result=re.findall('[^aeiou].+?[^aeiou]', word)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('io', 549),\n",
       " ('ea', 476),\n",
       " ('ie', 331),\n",
       " ('ou', 329),\n",
       " ('ai', 261),\n",
       " ('ia', 253),\n",
       " ('ee', 217),\n",
       " ('oo', 174),\n",
       " ('ua', 109),\n",
       " ('au', 106)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wsj=sorted(set(nltk.corpus.treebank.words()))\n",
    "fdist=nltk.FreqDist(vs for word in wsj for vs in re.findall(r'[aeiou]{2,}',word))\n",
    "fdist.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package udhr to\n",
      "[nltk_data]     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package udhr is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('udhr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이번에는 조금 다른 작업을 해보자. 정규표현식에 대소문자 모음이 앞에오든 가운데오든 뒤에오든 모든 모음을 우선 설정하였다. 그 뒤 compress함수를 설정하였는데, 이렇게 찾은 모음을 포함한 모든 요소를 pieces로 나눈 후 regexp에서 규정한 모음들만 찾은 뒤 리턴값으로 ''즉, 공백을 받은 뒤 그 피쓰들을 다시 재조립했다. 그리고 udhr패키지를 사용한 작업75까지의 인덱스에 해당하는 단어들을 전부 프린트했더니 아래와 같은 결과가 나왔다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unvrsl Dclrtn of Hmn Rghts Prmble Whrs rcgntn of the inhrnt dgnty and\n",
      "of the eql and inlnble rghts of all mmbrs of the hmn fmly is the fndtn\n",
      "of frdm , jstce and pce in the wrld , Whrs dsrgrd and cntmpt fr hmn\n",
      "rghts hve rsltd in brbrs acts whch hve outrgd the cnscnce of mnknd ,\n",
      "and the advnt of a wrld in whch hmn bngs shll enjy frdm of spch and\n"
     ]
    }
   ],
   "source": [
    "regexp = r'^[AEIOUaeiou]+|[AEIOUaeiou]+$|[^AEIOUaeiou]'\n",
    "def compress(word):\n",
    "    pieces = re.findall(regexp, word)\n",
    "    return ''.join(pieces)\n",
    "\n",
    "english_udhr = nltk.corpus.udhr.words('English-Latin1')\n",
    "print(nltk.tokenwrap(compress(w) for w in english_udhr[:75]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "쉬운 설명을 위해 예를 들어봤다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'abrcdbra'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compress('abracadabra')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "원래 English-Latin1 이 무엇인지를 보니, 우리는 위에서 regexp가 '모든 모음을 소거하는 작업'을 실행했다는 점을 알 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Universal',\n",
       " 'Declaration',\n",
       " 'of',\n",
       " 'Human',\n",
       " 'Rights',\n",
       " 'Preamble',\n",
       " 'Whereas',\n",
       " 'recognition',\n",
       " 'of',\n",
       " 'the',\n",
       " 'inherent',\n",
       " 'dignity',\n",
       " 'and',\n",
       " 'of',\n",
       " 'the',\n",
       " 'equal',\n",
       " 'and',\n",
       " 'inalienable',\n",
       " 'rights',\n",
       " 'of',\n",
       " 'all',\n",
       " 'members',\n",
       " 'of',\n",
       " 'the',\n",
       " 'human',\n",
       " 'family',\n",
       " 'is',\n",
       " 'the',\n",
       " 'foundation',\n",
       " 'of',\n",
       " 'freedom',\n",
       " ',',\n",
       " 'justice',\n",
       " 'and',\n",
       " 'peace',\n",
       " 'in',\n",
       " 'the',\n",
       " 'world',\n",
       " ',',\n",
       " 'Whereas',\n",
       " 'disregard',\n",
       " 'and',\n",
       " 'contempt',\n",
       " 'for',\n",
       " 'human',\n",
       " 'rights',\n",
       " 'have',\n",
       " 'resulted',\n",
       " 'in',\n",
       " 'barbarous',\n",
       " 'acts',\n",
       " 'which',\n",
       " 'have',\n",
       " 'outraged',\n",
       " 'the',\n",
       " 'conscience',\n",
       " 'of',\n",
       " 'mankind',\n",
       " ',',\n",
       " 'and',\n",
       " 'the',\n",
       " 'advent',\n",
       " 'of',\n",
       " 'a',\n",
       " 'world',\n",
       " 'in',\n",
       " 'which',\n",
       " 'human',\n",
       " 'beings',\n",
       " 'shall',\n",
       " 'enjoy',\n",
       " 'freedom',\n",
       " 'of',\n",
       " 'speech',\n",
       " 'and']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english_udhr = nltk.corpus.udhr.words('English-Latin1')\n",
    "english_udhr[:75]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package toolbox to\n",
      "[nltk_data]     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\toolbox.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('toolbox')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rotokas 사전(제가 알기로 사전의 일종인데 케임브리지대학에서 만든 사전이라고 알고 있습니다) 에서 kprstv와aeiou 조합의 단어들의 사용빈도를 표로 나타냈다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    a   e   i   o   u \n",
      "k 418 148  94 420 173 \n",
      "p  83  31 105  34  51 \n",
      "r 187  63  84  89  79 \n",
      "s   0   0 100   2   1 \n",
      "t  47   8   0 148  37 \n",
      "v  93  27 105  48  49 \n"
     ]
    }
   ],
   "source": [
    "rotokas_words=nltk.corpus.toolbox.words('rotokas.dic')\n",
    "cvs=[cv for w in rotokas_words for cv in re.findall(r'[kprstv][aeiou]',w)]\n",
    "cfd=nltk.ConditionalFreqDist(cvs)\n",
    "cfd.tabulate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "po 를 포함하면서 위 조건을 만족시키는 모든 요소들을 리스트로 받아냈다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['kaapo',\n",
       " 'kaapopato',\n",
       " 'kaipori',\n",
       " 'kaiporipie',\n",
       " 'kaiporivira',\n",
       " 'kapo',\n",
       " 'kapoa',\n",
       " 'kapokao',\n",
       " 'kapokapo',\n",
       " 'kapokapo',\n",
       " 'kapokapoa',\n",
       " 'kapokapoa',\n",
       " 'kapokapora',\n",
       " 'kapokapora',\n",
       " 'kapokaporo',\n",
       " 'kapokaporo',\n",
       " 'kapokari',\n",
       " 'kapokarito',\n",
       " 'kapokoa',\n",
       " 'kapoo',\n",
       " 'kapooto',\n",
       " 'kapoovira',\n",
       " 'kapopaa',\n",
       " 'kaporo',\n",
       " 'kaporo',\n",
       " 'kaporopa',\n",
       " 'kaporoto',\n",
       " 'kapoto',\n",
       " 'karokaropo',\n",
       " 'karopo',\n",
       " 'kepo',\n",
       " 'kepoi',\n",
       " 'keposi',\n",
       " 'kepoto']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_word_pairs=[(cv,w)for w in rotokas_words for cv in re.findall(r'[kprtsv][aeiou]',w)]\n",
    "cv_index=nltk.Index(cv_word_pairs)\n",
    "cv_index['po']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
